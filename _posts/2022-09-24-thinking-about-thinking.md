---
layout: post
title: Thinking About Thinking (Metacognition)
category: productivity
---

In this post, I explore the notion that we can observe experts in different fields and distill their underlying patterns of thought via the right syntax in order to adapt the "optimal style of thought" for that field (e.g natural sciences, computation, humanities).
<!--more-->


## The main idea

I posit these patterns of thought can be captured by invoking the right word. The idea is illustrated below in this quote by Henri Poincaré in _Science & Method_:

> We have just seen, through an example, how important words are in Mathematics, but I could cite many others. One can hardly believe how a well-chosen word can provide economy of thought, as Mach said. 

<center>
<img src="{{ site.imageurl }}/Metacognition/henri-poincare.jpg" style="width:50%;"/>
<figcaption>Henri Poincaré 1854-1912</figcaption>
</center>

Thus, by observing experts and choosing the right words they use, we can in theory, improve our learning speeds as well. But how do these <em>patterns of thought</em> explain the learning process? We can also distill the learning process like so:

<ul>
<li>Space of Knowledge - There is a space of knowledge that exists. </li>
<li>Sampling - People sample from the space of knowledge.</li>
<li>Application - People apply their <em>patterns of thought</em> to the knowledge to build their own understanding (knowledge graph).</li>
</ul>
                
<br>
## Phenomena

<p>Phenomena, or knowledge, represents the collection of different subjects of study. I define three categories: deterministic, semi-deterministic, and humanistic phenomena.</p>
<img src="{{ site.imageurl }}Metacognition/Page1B.png" height=350 class="center"> 

<p><b>Deterministic</b> phenomena have fixed laws that dont change over time - they are invariant. This description generally describes fields that study fixed laws of nature - <i>mathematics, natural sciences and engineering</i>. </p>

<p><b>Semi-deterministic</b> phenomena have laws that are manmade abstractions (and hence can be modified at will, say via a programming language). This generally describes the field of <i>computing</i>.</p>

<p><b>Humanistic</b> phenomena arise from human interactions which are weakly deterministic. The ‘laws’ constantly change and cannot be formalized. This phenomena generally describes these fields:
<i>history, economics and politics</i>.</p>

I propose that each phenomena can be thought of in two ways: a <i>primal form</i>, involving concepts and their connections as a <i>graph</i>, and a <i>dual</i> form, involving <i>visualising</i> these phenomena in real-time.

<h3>Primal Form: Graphs</h3>

<p>My idea is that understanding complexity is about linking things together, but each field has with different things, and how they are linked are different. Hence, we must examine both things and links. The more complex/detailed your internal model is of things and links, the better your understanding.</p>
<br>
<h2>Deterministic Framework</h2>
<p>Example Fields: Mathematics, natural sciences, engineering.</p>

<p>We define two types of atomic nodes: <i>concepts</i> and <i>measurements</i>. They can be represented with words (or symbols):</p>

<blockquote>
<i>Atom: Concept/Measurement</i> - An abstract concept, or a physical measurement/variable.
</blockquote>
<p>We can then <i>connect</i> concepts or measurements to each other.</p>
<blockquote>
<i>Edge: Connection</i> - Connect concepts/measurements to each other
</blockquote>
<p>The result being:</p>
<blockquote>
<i>Graph: Proofs, theorems, equations</i> - The result of connecting various measurements or concepts together.
</blockquote>
<p>A connection can be <em>direct</em> or <em>latent</em>.</p>
<ul>
<li><em>Direct</em> connections are obvious and well-defined. If one concept or measurement is defined in terms of several others - then it is a direct connection.</li>
<li><em>Latent</em> connections are connections that are not explicitly defined. They represent similarities or links between concepts that one can form via some sudden realization. Often times, one makes latent connections between two seeming unrelated concepts in different fields.</li>
</ul>
<p>Furthermore, the connections should be dense and near. Dense meaning for a given space, the amount of connections is large. Near meaning for a given two points in space, one forms a chain of many small connections to get from one point to another.
</p>

<br>
<h2>Deterministic Evidence</h2>
<p>To explain how I derived the notion of concepts and connections, we turn to this video:  <a href="https://www.youtube.com/watch?v=2y2sGLM0WGY&amp;ab_channel=Breakthrough">Breakthrough Prize in Mathematics 2014</a>. </p>
<blockquote>
<p>There are moments where you <i>put something together</i> and realize this is how the story has to go.</p>
</blockquote>
<figcaption>—Jacob Lurie, <cite><a href="https://www.youtube.com/watch?v=r_gCOs6vLzE&ab_channel=InstitutdesHautes%C3%89tudesScientifiques%28IH%C3%89S%29&t=135">Breakthrough Prize Acceptance (2:15)</a></cite></figcaption>
And
<blockquote>
<p> There is a beauty in the way things <i>fit together in an unexpected way</i>.</p>
</blockquote>
<figcaption>—Richard Taylor, <cite><a href="https://www.youtube.com/watch?v=r_gCOs6vLzE&ab_channel=InstitutdesHautes%C3%89tudesScientifiques%28IH%C3%89S%29&t=120">Breakthrough Prize Acceptance (2:00)</a></cite></figcaption>
<!-- <p>Similarly, things fitting together in an unexpected way implies drawing new connections between concepts were previously there were none! The same idea is expressed by both mathematicians.</p> -->
<!-- <p><i>[GRAPHIC HERE - latent connections]</i></p> -->
<p>Notice the choice of words in bold: they imply connecting something (ideas/concepts) together. </p>
<p>Next, we turn to Feynman.</p>
<blockquote>
<p>Atoms in the coffee jiggle, which makes the cup jiggle. Heat is just jiggling spreading, which is easy to understand.</p>
</blockquote>
<figcaption>—Richard Feynman, <cite><a href="https://www.youtube.com/watch?v=P1ww1IXRfTA&ab_channel=ChristopherSykes&t=80">Fun to Imagine (1:20)</a></cite></figcaption>
And
<blockquote>
<p> It's a mixture of partial solving of equations ... and having some sort of <i>picture</i> of what's happening that the equations saying.</p>
</blockquote>
<figcaption>—Richard Feynman, <cite><a href="https://www.youtube.com/watch?v=P1ww1IXRfTA&ab_channel=ChristopherSykes&t=3378">Fun to Imagine (56:18)</a></cite></figcaption>
<p>Feynman explains heat a bunch of atoms jiggling and spreading their jiggling to others via contact. Now, indirectly, he is imagining a measurement (the jiggling) and showing how that interacts with another measurement (another bunch of atoms jiggling). </p>

<br>

# Semideterministic Framework

<p>For semi-deterministic phenomena, the basic unit (node) is <i>data</i>.</p>
<blockquote>
Unit: Data/Memory This can be visualised as anything, really. Arrays, nodes, boxes, whatever.
</blockquote>
<p>Well, what do we do with it? It interacts with a black box, called an operation, which interacts with another node of data!</p>

<blockquote>
Edge: Interaction/Black Box - Visualised as a small pipe with any number of data inputs and outputs. The job of the box is to take in some inputs and produce some outputs. The key idea is it connects two or more nodes of data together via an interaction.
</blockquote>     

We can also decompose an edge:

<blockquote>
Decomposition/Breaking Down - Peering inside a pipe and breaking it into more data and pipes. 
</blockquote>

<p>So, we start with a given problem, how to take some inputs and get some outputs we want. There's the pipe, from the top-down approach. We then break it down into smaller pieces, and those smaller pieces into smaller pieces, 
so on and so forth, in a <i>top-down</i> fashion.
</p>   

<h2>Semideterministic Evidence</h2>
<p>For data as an atom, the core idea comes from this video from George Hotz livestream:</p>
<blockquote>
Input → system (computation) → output. This is my core paradigm for understanding anything.
</blockquote>
<figcaption>—George Hotz, <cite><a href="https://www.youtube.com/watch?v=N2bXEUSAiTI&ab_channel=georgehotzarchive&t=3240">What is Programming? (Noob Lessons!) (54:00)</a></cite></figcaption>
<p>Hotz states the idea clearly here - its all about thinking in terms of inputs and outputs.</p>

<p>Next, they interact to form computation/abstraction layers. Jim Keller and Donald Knuth both express this idea independently:
<blockquote>
There's a relatively good understanding of <i>abstraction layers</i>. Atoms, silicon, transistors, logic gates, functional units, processing elements, instruction sets, languages - abstraction layers from the atom to the datacenter. 
</blockquote>
<figcaption>—Jim Keller, <cite><a href="https://www.youtube.com/watch?v=Nb2tebYAaOA&ab_channel=LexFridman&t=250">Jim Keller | Lex Fridman Podcast #70 (4:10)</a></cite></figcaption>

And
<blockquote>
Being able to see something at lots of levels and <i>go between them smoothly</i> seems to be more pronounced in people that resonate with computing
</blockquote>
<figcaption>—Donald Knuth, <cite><a href="https://www.youtube.com/watch?v=2BdBfsXbST8&ab_channel=LexFridman&t=553">Donald Knuth | Lex Fridman Podcast #62 (9:13)</a></cite></figcaption>

<p>Clearly, the idea is to exhibit top-down thinking. For example, deconstructing a unit of data into further units, or a computation into further computation steps.</p>
<br>
<h2>Humanistic Framework</h2>

<p>This is tough. As mentioned, these types of phenomena are related to human behavior. For example, economics, discretionary trading, (geo)politics, organisational dynamics, etc. In these cases, the unit is the actor.</p>
<blockquote>
Unit: Actor - A person or collective entity. Actors have a utility function, a perspective and can perform actions. Who or what?
</blockquote>
<p>Then, actors interact:</p>
<blockquote>
Edge: Interaction - An actor performs an action. This is an edge that propagates to other actors, which in turn modifies their perspective and they take action. Why did x do this?
</blockquote>
<p>The result being: </p>
<blockquote>
Graph: Situation - A situation arising from multiple actors interacting
</blockquote>

<p>As of November 2023, I have been thinking about this part of the framework. This is the most difficult framework to formalize. I believe, very strongly, that the masters of this style of thinking are often found in finance, 
in particular discretionary trading. This is because markets are simply a collection of actors performing actions based on different views and intentions.</p>

<h2>Humanistic Evidence</h2>

<p>This idea came from <em>Soros The Alchemy of Finance</em>:</p>
<blockquote>
<p>My framework is built on two propositions. The first is that in situations that have thinking <i>participants</i>, the participants’ <i>views</i> of the world never perfectly correspond to the actual state of affairs.
The second proposition is that these imperfect views can influence the situation to which they relate through the <i>actions</i> of the participants.</p>
</blockquote>
<figcaption>—George Soros, <cite><a href="https://www.georgesoros.com/2014/01/13/fallibility-reflexivity-and-the-human-uncertainty-principle-2/">Fallibility, Reflexivity, and the Human Uncertainty Principle</a></cite></figcaption>
<p>Note the key terms used - Soros thinks in terms of participants (actors) and their actions.</p>

<h2>Visualisation: dual form</h2>

<p>The counterpart to the graph is to visualise these phenomena in real time. The primal form deals with symbols and words, the dual form visualises them. </p>
<p>For deterministic phenomena, basically math and physics (placeholder for science since it is the most fundamental discipline), we want to visualise concepts or variables. The more complex or fine-grained the simulation, the better. Basically, we parameterize elements in the simulation by numbers.</p>
<p>For semideterministic phenomena, basically computer science, we want to visualise how data is transformed. This visualisation is done at a level of abstraction, meaning what we visualise is not what is physically occuring.</p>
<p>For humanistic phenomena, I do not know how to capture this idea but I believe it involves visualising actors and actions as a graph/mindmap of sorts. </p>

<h2>Conclusion </h2>

<p>To sum up this post, I propose we can classify subjects into: deterministic (natural sciences), semi-deterministic (computation), humanistic (humanities). Each type has an optimal way of thinking, different from the other,
which we can distill by observing experts in each subject and extrapolating their thought process via the correct syntax. Am I nuts? Probably.  </p>

